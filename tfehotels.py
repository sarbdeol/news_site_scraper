import csv
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from datetime import datetime
from insert_csv_into_sql_db import check_and_remove_file, append_unique_records,generate_news, generate_subtitle, generate_title, insert_csv_data, generate_random_filename
from upload_and_reference import upload_photo_to_ftp
from insert_csv_into_sql_db import date_format,download_image
from selenium.webdriver.chrome.options import Options

from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium import webdriver
from dotenv import load_dotenv


# Load environment variables from .env file
load_dotenv()

# Set up Chrome options for headless mode
chrome_options = Options()
chrome_options.add_argument("--headless")  # Run Chrome in headless mode (no UI)
chrome_options.add_argument("--disable-gpu")  # Disable GPU usage (optional, improves performance)
chrome_options.add_argument("--no-sandbox")  # Recommended for headless mode in some environments
chrome_options.add_argument("--disable-dev-shm-usage")  # Prevent shared memory issues
chrome_options.add_argument("--window-size=1920,1080")  # Set the window size for screenshots

# Specify the path to your ChromeDriver executable
chromedriver_path = "/usr/local/bin/chromedriver"  # Replace with the actual path to ChromeDriver

# Set up the WebDriver with Chrome options
service = Service(chromedriver_path)
driver = webdriver.Chrome(service=service, options=chrome_options)

# Define CSV headers
headers = [
    "id", "title", "subtitle", "slug", "lead", "content", "image", "type",
    "custom_field", "parent_id", "created_at", "updated_at", "added_timestamp",
    "language", "seo_title", "seo_content", "seo_title_desc",
    "seo_content_desc", "category_id"
]



# Navigate to the page
driver.get("https://www.tfehotels.com/en/press/")  # Replace with the actual URL of the page containing the list

# Wait for the <li> elements to load
WebDriverWait(driver, 30).until(
    EC.presence_of_element_located((By.CSS_SELECTOR, 'li'))
)

# JavaScript to get the href of the most recent link
js_code = """
const recentLink = document.querySelector('li a.btn.read-more');
if (recentLink) {
    return recentLink.href; // Return the href attribute
} else {
    return null; // Return null if no link is found
}
"""

# Execute the JavaScript code
most_recent_href = driver.execute_script(js_code)

if most_recent_href:
    print(f"Opening the most recent link: {most_recent_href}")
    driver.get(most_recent_href)  # Open the extracted URL in the browser

    # JavaScript to get the title and date
    js_code = """
    const titleElement = document.querySelector('h1');
    const title = titleElement ? titleElement.childNodes[0].nodeValue.trim() : null; // Extract text before <time>
    const dateElement = titleElement ? titleElement.querySelector('time') : null;
    const date = dateElement ? dateElement.innerText.trim() : null;

    return { title, date }; // Return an object with the title and date
    """

    # Execute the JavaScript code
    result = driver.execute_script(js_code)

    # Extract title and date
    title = generate_title(result.get('title'))
    date = date_format(result.get('date'))
    print(date)

    # JavaScript to get the image URL
    js_code = """
    const imgElement = document.querySelector('img');
    if (imgElement) {
        return imgElement.getAttribute('data-cfsrc') || imgElement.src; // Prefer data-cfsrc if available, otherwise fall back to src
    } else {
        return null; // Return null if no <img> tag is found
    }
    """

    # Execute the JavaScript code
    image_url = driver.execute_script(js_code)

    img_nam = generate_random_filename()

    download_image(image_url,img_nam)

    # upload_photo_to_ftp(img_nam,"/public_html/storage/information/")

    # JavaScript to get all <p> tag contents
    js_code = """
    let pTags = document.querySelectorAll('p'); // Select all <p> tags
    let pContent = []; // Initialize an array to store content

    // Loop through each <p> tag and extract the text content
    pTags.forEach(p => {
        pContent.push(p.innerText.trim()); // Trim the text to remove extra spaces
    });

    // Return the content as a single string joined by newlines
    return pContent.join('\\n');
    """

    # Execute the JavaScript code
    p_tags_content = generate_news(driver.execute_script(js_code))

    # Save the data to CSV file
    data_row = [
        1,  # id (optional, can be autogenerated or fetched from other sources)
        title,  # title
        generate_subtitle(title),  # subtitle
        title.lower().replace(" ","-"),  # slug
        None,  # lead
        p_tags_content,  # content
        "information/"+img_nam,  # image
        None,  # type
        None,  # custom_field
        None,  # parent_id
        date,  # created_at
        datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # updated_at
        date,  # added_timestamp (current time)
        "en",  # language (assumed to be English)
        None,  # seo_title
        None,  # seo_content
        None,  # seo_title_desc
        None,  # seo_content_desc
        100   # category_id
    ]

    # Write the data to CSV file
    with open("tfehotels_press_data.csv", mode="a", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        if file.tell() == 0:  # Write headers only if the file is empty
            writer.writerow(headers)
        writer.writerow(data_row)

    print("Data saved to CSV.")

else:
    print("No recent link found.")

# Close the driver when done
driver.quit()


if date==date_format(datetime.now().today()):
    # Insert the CSV data into the database
    upload_photo_to_ftp(img_nam,"/public_html/storage/information/")
    insert_csv_data("tfehotels_press_data.csv", "informations")
    append_unique_records("tfehotels_press_data.csv","combined_news_data.csv")

else:
    print("--------WE DO NOT HAVE DATA FOR TODAY--------")